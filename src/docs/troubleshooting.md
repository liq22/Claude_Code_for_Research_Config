# ğŸ”§ æ•…éšœæ’æŸ¥æŒ‡å—

å¸¸è§é—®é¢˜çš„å¿«é€Ÿè¯Šæ–­ä¸è§£å†³æ–¹æ¡ˆã€‚

## ğŸš¨ ç´§æ€¥é—®é¢˜å¿«é€Ÿç´¢å¼•

### âš¡ ç³»ç»Ÿæ€§èƒ½é—®é¢˜
- [Claudeå“åº”ç¼“æ…¢](#claudeå“åº”ç¼“æ…¢) 
- [å†…å­˜ä¸è¶³é”™è¯¯](#å†…å­˜ä¸è¶³é”™è¯¯)
- [GPUèµ„æºå ç”¨è¿‡é«˜](#gpuèµ„æºå ç”¨è¿‡é«˜)
- [ç½‘ç»œè¿æ¥è¶…æ—¶](#ç½‘ç»œè¿æ¥è¶…æ—¶)

### ğŸ“ æ–‡æ¡£ç”Ÿæˆé—®é¢˜  
- [ç”Ÿæˆå†…å®¹è´¨é‡ä¸ä½³](#ç”Ÿæˆå†…å®¹è´¨é‡ä¸ä½³)
- [æ ¼å¼æ··ä¹±é”™è¯¯](#æ ¼å¼æ··ä¹±é”™è¯¯)
- [å¼•ç”¨æ ¼å¼é”™è¯¯](#å¼•ç”¨æ ¼å¼é”™è¯¯)
- [å›¾è¡¨æ˜¾ç¤ºå¼‚å¸¸](#å›¾è¡¨æ˜¾ç¤ºå¼‚å¸¸)

### ğŸ’» ä»£ç æ‰§è¡Œé—®é¢˜
- [Pythonç¯å¢ƒé”™è¯¯](#pythonç¯å¢ƒé”™è¯¯)
- [ä¾èµ–åŒ…å†²çª](#ä¾èµ–åŒ…å†²çª)  
- [è„šæœ¬æ‰§è¡Œå¤±è´¥](#è„šæœ¬æ‰§è¡Œå¤±è´¥)
- [æƒé™è®¿é—®é”™è¯¯](#æƒé™è®¿é—®é”™è¯¯)

### ğŸ” æœç´¢åŠŸèƒ½é—®é¢˜
- [æ–‡çŒ®æœç´¢ç»“æœè¿‡å°‘](#æ–‡çŒ®æœç´¢ç»“æœè¿‡å°‘)
- [æœç´¢ç»“æœä¸ç›¸å…³](#æœç´¢ç»“æœä¸ç›¸å…³)
- [æ•°æ®åº“è®¿é—®å¤±è´¥](#æ•°æ®åº“è®¿é—®å¤±è´¥)
- [æœç´¢é€Ÿåº¦è¿‡æ…¢](#æœç´¢é€Ÿåº¦è¿‡æ…¢)

---

## ğŸ–¥ï¸ ç³»ç»Ÿæ€§èƒ½é—®é¢˜

### Claudeå“åº”ç¼“æ…¢

#### ğŸ” é—®é¢˜ç—‡çŠ¶
```
- ç­‰å¾…æ—¶é—´è¶…è¿‡2åˆ†é’Ÿ
- ç³»ç»Ÿæ˜¾ç¤º"æ­£åœ¨å¤„ç†"ä½†æ— è¿›å±•
- éƒ¨åˆ†å“åº”ä¸å®Œæ•´
- é¢‘ç¹å‡ºç°è¶…æ—¶é”™è¯¯
```

#### ğŸ› ï¸ è¯Šæ–­æ­¥éª¤
```
1. æ£€æŸ¥ç½‘ç»œè¿æ¥
   - æµ‹è¯•ç½‘ç»œå»¶è¿Ÿ: ping claude.ai
   - æ£€æŸ¥å¸¦å®½ä½¿ç”¨æƒ…å†µ
   - ç¡®è®¤é˜²ç«å¢™è®¾ç½®

2. ç³»ç»Ÿèµ„æºæ£€æŸ¥  
   - CPUä½¿ç”¨ç‡: task manager / top
   - å†…å­˜ä½¿ç”¨é‡: å¯ç”¨RAM < 2GB
   - ç£ç›˜ç©ºé—´: å‰©ä½™ç©ºé—´ < 1GB

3. è¯·æ±‚å¤æ‚åº¦åˆ†æ
   - å•æ¬¡è¯·æ±‚é•¿åº¦ > 10,000å­—ç¬¦
   - å¹¶å‘è¯·æ±‚æ•°é‡ > 3ä¸ª
   - æ¶‰åŠå¤§æ–‡ä»¶å¤„ç†
```

#### âœ… è§£å†³æ–¹æ¡ˆ
```
immediate ç«‹å³æªæ–½:
1. åˆ·æ–°é¡µé¢é‡æ–°å¼€å§‹
2. å…³é—­å…¶ä»–æµè§ˆå™¨æ ‡ç­¾é¡µ
3. é‡å¯Claude Codeåº”ç”¨

short-term çŸ­æœŸä¼˜åŒ–:
1. åˆ†è§£å¤æ‚ä»»åŠ¡ä¸ºå°å—
2. é¿å…åŒæ—¶æ‰§è¡Œå¤šä¸ªä»»åŠ¡  
3. æ¸…ç†æœ¬åœ°ç¼“å­˜æ–‡ä»¶

long-term é•¿æœŸæ”¹å–„:
1. å‡çº§ç½‘ç»œå¸¦å®½
2. å¢åŠ ç³»ç»ŸRAM
3. ä½¿ç”¨SSDæå‡I/Oé€Ÿåº¦
```

### å†…å­˜ä¸è¶³é”™è¯¯

#### ğŸ” é—®é¢˜ç—‡çŠ¶
```
- "å†…å­˜ä¸è¶³"é”™è¯¯æç¤º
- ç³»ç»Ÿå¡é¡¿ä¸¥é‡
- ç¨‹åºæ„å¤–ç»ˆæ­¢
- æ–‡ä»¶ä¿å­˜å¤±è´¥
```

#### ğŸ› ï¸ è§£å†³æ–¹æ¡ˆ
```python
# å†…å­˜ä½¿ç”¨ä¼˜åŒ–
import gc
import psutil

def check_memory():
    """æ£€æŸ¥å½“å‰å†…å­˜ä½¿ç”¨æƒ…å†µ"""
    memory = psutil.virtual_memory()
    print(f"å¯ç”¨å†…å­˜: {memory.available / 1024**3:.2f} GB")
    print(f"ä½¿ç”¨ç‡: {memory.percent}%")
    
    if memory.percent > 80:
        print("âš ï¸ å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜ï¼Œå»ºè®®æ¸…ç†")
        return False
    return True

def optimize_memory():
    """ä¼˜åŒ–å†…å­˜ä½¿ç”¨"""
    # å¼ºåˆ¶åƒåœ¾å›æ”¶
    gc.collect()
    
    # æ¸…ç†å¤§å‹å˜é‡
    # del large_variables
    
    # åˆ†æ‰¹å¤„ç†æ•°æ®
    chunk_size = 1000  # è°ƒæ•´æ‰¹æ¬¡å¤§å°
```

#### âœ… ç³»ç»Ÿçº§è§£å†³æ–¹æ¡ˆ
```bash
# Linux/Macç³»ç»Ÿä¼˜åŒ–
# 1. å¢åŠ è™šæ‹Ÿå†…å­˜
sudo swapon --show
sudo fallocate -l 4G /swapfile
sudo chmod 600 /swapfile
sudo mkswap /swapfile
sudo swapon /swapfile

# 2. æ¸…ç†ç³»ç»Ÿç¼“å­˜
sudo sync && echo 3 | sudo tee /proc/sys/vm/drop_caches

# 3. å…³é—­ä¸å¿…è¦çš„æœåŠ¡
systemctl list-units --type=service --state=running
```

### GPUèµ„æºå ç”¨è¿‡é«˜

#### ğŸ” é—®é¢˜è¯Šæ–­
```bash
# æ£€æŸ¥GPUä½¿ç”¨æƒ…å†µ
nvidia-smi

# æŒç»­ç›‘æ§
watch -n 1 nvidia-smi

# æŸ¥çœ‹å ç”¨GPUçš„è¿›ç¨‹
fuser -v /dev/nvidia*
```

#### âœ… è§£å†³æ–¹æ¡ˆ
```python
# GPUå†…å­˜ä¼˜åŒ–
import torch

def optimize_gpu_memory():
    """ä¼˜åŒ–GPUå†…å­˜ä½¿ç”¨"""
    if torch.cuda.is_available():
        # æ¸…ç©ºGPUç¼“å­˜
        torch.cuda.empty_cache()
        
        # æ£€æŸ¥GPUå†…å­˜
        allocated = torch.cuda.memory_allocated() / 1024**3
        cached = torch.cuda.memory_reserved() / 1024**3
        
        print(f"GPUå†…å­˜å·²åˆ†é…: {allocated:.2f} GB")
        print(f"GPUå†…å­˜ç¼“å­˜: {cached:.2f} GB")
        
        # è®¾ç½®å†…å­˜å¢é•¿ç­–ç•¥
        torch.cuda.set_per_process_memory_fraction(0.8)

# æ¨¡å‹ä¼˜åŒ–æŠ€å·§
def train_with_memory_optimization(model, data_loader):
    """å†…å­˜ä¼˜åŒ–çš„è®­ç»ƒå¾ªç¯"""
    for batch in data_loader:
        # ä½¿ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹
        with torch.no_grad():
            # æ¨ç†é˜¶æ®µ
            pass
        
        # åŠæ—¶åˆ é™¤ä¸­é—´å˜é‡
        del batch
        torch.cuda.empty_cache()
```

---

## ğŸ“ æ–‡æ¡£ç”Ÿæˆé—®é¢˜

### ç”Ÿæˆå†…å®¹è´¨é‡ä¸ä½³

#### ğŸ” é—®é¢˜ç—‡çŠ¶
```
- å†…å®¹è¿‡äºç®€å•æˆ–é‡å¤
- ç¼ºä¹ä¸“ä¸šæ·±åº¦
- é€»è¾‘ç»“æ„æ··ä¹±
- è¯­è¨€è¡¨è¾¾ä¸å‡†ç¡®
```

#### âœ… ä¼˜åŒ–ç­–ç•¥
```markdown
# æå‡è¾“å…¥è´¨é‡
## è¯¦ç»†èƒŒæ™¯ä¿¡æ¯
"æˆ‘æ˜¯[ä¸“ä¸šèƒŒæ™¯]ï¼Œç ”ç©¶é¢†åŸŸæ˜¯[å…·ä½“æ–¹å‘]ï¼Œ
å½“å‰é¡¹ç›®æ¶‰åŠ[æŠ€æœ¯ç»†èŠ‚]ï¼Œç›®æ ‡æœŸåˆŠæ˜¯[æœŸåˆŠåç§°]"

## æ˜ç¡®å…·ä½“éœ€æ±‚
âŒ ä¸å¥½: "å†™ä¸ªå¼•è¨€"
âœ… è‰¯å¥½: "ä¸ºtransformeræ³¨æ„åŠ›æœºåˆ¶ä¼˜åŒ–çš„Nature AIè®ºæ–‡å†™å¼•è¨€ï¼Œ
åŒ…å«èƒŒæ™¯ã€ç°æœ‰æ–¹æ³•å±€é™ã€æˆ‘ä»¬çš„è´¡çŒ®"

## æä¾›ä¸Šä¸‹æ–‡
- ç›¸å…³è®ºæ–‡å’Œå¼•ç”¨
- å®éªŒæ•°æ®å’Œç»“æœ  
- æŠ€æœ¯ç»†èŠ‚å’Œå‚æ•°
- ç›®æ ‡è¯»è€…å’ŒæœŸåˆŠè¦æ±‚
```

#### ğŸ”„ è¿­ä»£æ”¹è¿›æµç¨‹
```
åˆå§‹ç”Ÿæˆ â†’ è´¨é‡è¯„ä¼° â†’ å…·ä½“åé¦ˆ â†’ é‡æ–°ç”Ÿæˆ â†’ æŒç»­ä¼˜åŒ–

ç¤ºä¾‹åé¦ˆ:
"è¿™ä¸ªå¼•è¨€éœ€è¦æ›´å¤šæŠ€æœ¯æ·±åº¦ï¼Œè¯·æ·»åŠ ï¼š
1. å…·ä½“çš„æ€§èƒ½æ•°æ®å¯¹æ¯”
2. æ›´è¯¦ç»†çš„æ–¹æ³•æè¿°
3. ä¸æœ€æ–°ç ”ç©¶çš„å…³è”
4. æ›´å¼ºçš„åˆ›æ–°æ€§è¡¨è¿°"
```

### æ ¼å¼æ··ä¹±é”™è¯¯

#### ğŸ” å¸¸è§æ ¼å¼é—®é¢˜
```
- æ ‡é¢˜å±‚çº§æ··ä¹±
- å¼•ç”¨æ ¼å¼ä¸ä¸€è‡´
- å›¾è¡¨ç¼–å·é”™è¯¯
- æ•°å­¦å…¬å¼æ˜¾ç¤ºå¼‚å¸¸
```

#### âœ… æ ¼å¼è§„èŒƒåŒ–
```latex
% LaTeXæ ¼å¼æ¨¡æ¿
\documentclass[journal]{IEEEtran}

% æ ‡é¢˜å±‚çº§è§„èŒƒ
\section{Introduction}          % ä¸€çº§æ ‡é¢˜
\subsection{Related Work}       % äºŒçº§æ ‡é¢˜  
\subsubsection{Deep Learning}   % ä¸‰çº§æ ‡é¢˜

% å¼•ç”¨æ ¼å¼ç»Ÿä¸€
\bibliographystyle{IEEEtran}
\bibliography{references}

% å›¾è¡¨è§„èŒƒ
\begin{figure}[htbp]
\centering
\includegraphics[width=0.8\columnwidth]{figure.pdf}
\caption{Caption text here.}
\label{fig:label}
\end{figure}
```

#### ğŸ› ï¸ è‡ªåŠ¨æ ¼å¼æ£€æŸ¥
```python
def check_format_consistency(text):
    """æ£€æŸ¥æ ¼å¼ä¸€è‡´æ€§"""
    issues = []
    
    # æ£€æŸ¥æ ‡é¢˜å±‚çº§
    import re
    headers = re.findall(r'^#+\s+(.+)$', text, re.MULTILINE)
    
    # æ£€æŸ¥å¼•ç”¨æ ¼å¼
    citations = re.findall(r'\[(\d+)\]', text)
    
    # æ£€æŸ¥å›¾è¡¨ç¼–å·
    figures = re.findall(r'Figure\s+(\d+)', text)
    tables = re.findall(r'Table\s+(\d+)', text)
    
    return issues
```

### å¼•ç”¨æ ¼å¼é”™è¯¯

#### ğŸ” å¸¸è§å¼•ç”¨é—®é¢˜
```
- å¼•ç”¨æ ·å¼ä¸ä¸€è‡´: [1] vs (Smith, 2023)
- ç¼ºå°‘é¡µç ä¿¡æ¯
- ä½œè€…å§“åæ ¼å¼é”™è¯¯
- æœŸåˆŠåç§°ç¼©å†™ä¸è§„èŒƒ
```

#### âœ… æ ‡å‡†åŒ–è§£å†³æ–¹æ¡ˆ
```python
# ä½¿ç”¨æ ‡å‡†å¼•ç”¨ç®¡ç†
import pandas as pd

def standardize_citations(references):
    """æ ‡å‡†åŒ–å¼•ç”¨æ ¼å¼"""
    
    # APAæ ¼å¼æ¨¡æ¿
    apa_format = "{authors} ({year}). {title}. {journal}, {volume}({issue}), {pages}."
    
    # IEEEæ ¼å¼æ¨¡æ¿  
    ieee_format = "[{id}] {authors}, \"{title},\" {journal}, vol. {volume}, no. {issue}, pp. {pages}, {year}."
    
    # Natureæ ¼å¼æ¨¡æ¿
    nature_format = "{authors}. {title}. {journal} {volume}, {pages} ({year})."
    
    return formatted_refs

# è‡ªåŠ¨å¼•ç”¨æ£€æŸ¥
def validate_references(text, style='IEEE'):
    """éªŒè¯å¼•ç”¨æ ¼å¼"""
    patterns = {
        'IEEE': r'\[\d+\]',
        'APA': r'\([A-Za-z]+,\s+\d{4}\)',
        'Nature': r'[A-Za-z]+\s+et\s+al\.\s+\(\d{4}\)'
    }
    
    found_citations = re.findall(patterns[style], text)
    return len(found_citations)
```

---

## ğŸ’» ä»£ç æ‰§è¡Œé—®é¢˜

### Pythonç¯å¢ƒé”™è¯¯

#### ğŸ” é—®é¢˜ç—‡çŠ¶
```
- ModuleNotFoundError: No module named 'xxx'
- Pythonç‰ˆæœ¬ä¸å…¼å®¹
- è™šæ‹Ÿç¯å¢ƒæœªæ¿€æ´»
- åŒ…ç‰ˆæœ¬å†²çª
```

#### âœ… ç¯å¢ƒè¯Šæ–­ä¸ä¿®å¤
```bash
# 1. æ£€æŸ¥Pythonç¯å¢ƒ
python --version
which python
pip list

# 2. è™šæ‹Ÿç¯å¢ƒç®¡ç†
# åˆ›å»ºæ–°ç¯å¢ƒ
python -m venv research_env
source research_env/bin/activate  # Linux/Mac
# research_env\Scripts\activate   # Windows

# 3. å®‰è£…ä¾èµ–
pip install -r config/requirements.txt

# 4. ç¯å¢ƒéªŒè¯
python -c "import torch; print(torch.__version__)"
python -c "import numpy; print(numpy.__version__)"
```

#### ğŸ› ï¸ ç¯å¢ƒä¿®å¤è„šæœ¬
```python
#!/usr/bin/env python3
"""ç¯å¢ƒè¯Šæ–­å’Œä¿®å¤è„šæœ¬"""

import sys
import subprocess
import importlib.util

def check_python_version():
    """æ£€æŸ¥Pythonç‰ˆæœ¬"""
    version = sys.version_info
    if version.major < 3 or (version.major == 3 and version.minor < 8):
        print(f"âš ï¸ Pythonç‰ˆæœ¬è¿‡ä½: {version.major}.{version.minor}")
        return False
    print(f"âœ… Pythonç‰ˆæœ¬: {version.major}.{version.minor}.{version.micro}")
    return True

def check_required_packages():
    """æ£€æŸ¥å¿…éœ€åŒ…"""
    required = ['torch', 'numpy', 'pandas', 'matplotlib', 'scipy']
    missing = []
    
    for package in required:
        spec = importlib.util.find_spec(package)
        if spec is None:
            missing.append(package)
        else:
            print(f"âœ… {package} å·²å®‰è£…")
    
    if missing:
        print(f"âŒ ç¼ºå°‘åŒ…: {missing}")
        return False
    return True

def auto_fix_environment():
    """è‡ªåŠ¨ä¿®å¤ç¯å¢ƒ"""
    if not check_python_version():
        print("è¯·å‡çº§Pythonåˆ°3.8+")
        return
    
    if not check_required_packages():
        print("æ­£åœ¨å®‰è£…ç¼ºå°‘çš„åŒ…...")
        subprocess.run([sys.executable, '-m', 'pip', 'install', '-r', 'config/requirements.txt'])

if __name__ == "__main__":
    auto_fix_environment()
```

### ä¾èµ–åŒ…å†²çª

#### ğŸ” å†²çªè¯Šæ–­
```bash
# æ£€æŸ¥åŒ…ä¾èµ–æ ‘
pip show torch
pipdeptree

# æŸ¥æ‰¾å†²çª
pip check

# ç‰ˆæœ¬å…¼å®¹æ€§æ£€æŸ¥
pip list --outdated
```

#### âœ… è§£å†³ç­–ç•¥
```bash
# 1. åˆ›å»ºå¹²å‡€ç¯å¢ƒ
conda create -n clean_env python=3.9
conda activate clean_env

# 2. æŒ‰ä¼˜å…ˆçº§å®‰è£…
# é¦–å…ˆå®‰è£…æ ¸å¿ƒæ·±åº¦å­¦ä¹ æ¡†æ¶
pip install torch torchvision torchaudio

# ç„¶åå®‰è£…ç§‘å­¦è®¡ç®—åŒ…
pip install numpy scipy pandas matplotlib

# æœ€åå®‰è£…å…¶ä»–ä¾èµ–
pip install -r requirements_additional.txt

# 3. é”å®šç‰ˆæœ¬
pip freeze > requirements_locked.txt
```

### è„šæœ¬æ‰§è¡Œå¤±è´¥

#### ğŸ” å¸¸è§æ‰§è¡Œé”™è¯¯
```python
# æ–‡ä»¶è·¯å¾„é”™è¯¯
FileNotFoundError: [Errno 2] No such file or directory: 'data.csv'

# æƒé™é”™è¯¯  
PermissionError: [Errno 13] Permission denied: '/protected/file'

# ç¼–ç é”™è¯¯
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff

# å†…å­˜é”™è¯¯
MemoryError: Unable to allocate array
```

#### âœ… é€šç”¨ä¿®å¤æ–¹æ¡ˆ
```python
import os
import sys
from pathlib import Path

def robust_file_read(filepath, encodings=['utf-8', 'gbk', 'latin1']):
    """å¥å£®çš„æ–‡ä»¶è¯»å–"""
    filepath = Path(filepath)
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not filepath.exists():
        raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {filepath}")
    
    # æ£€æŸ¥æ–‡ä»¶æƒé™
    if not filepath.is_file():
        raise ValueError(f"ä¸æ˜¯æ–‡ä»¶: {filepath}")
    
    # å°è¯•ä¸åŒç¼–ç 
    for encoding in encodings:
        try:
            with open(filepath, 'r', encoding=encoding) as f:
                return f.read()
        except UnicodeDecodeError:
            continue
    
    raise UnicodeDecodeError("æ‰€æœ‰ç¼–ç æ–¹å¼éƒ½å¤±è´¥")

def safe_script_execution(script_path, **kwargs):
    """å®‰å…¨çš„è„šæœ¬æ‰§è¡Œ"""
    try:
        # è®¾ç½®å·¥ä½œç›®å½•
        original_cwd = os.getcwd()
        script_dir = Path(script_path).parent
        os.chdir(script_dir)
        
        # æ‰§è¡Œè„šæœ¬
        exec(compile(open(script_path).read(), script_path, 'exec'), kwargs)
        
    except Exception as e:
        print(f"è„šæœ¬æ‰§è¡Œå¤±è´¥: {e}")
        return False
    finally:
        # æ¢å¤å·¥ä½œç›®å½•
        os.chdir(original_cwd)
    
    return True
```

---

## ğŸ” æœç´¢åŠŸèƒ½é—®é¢˜

### æ–‡çŒ®æœç´¢ç»“æœè¿‡å°‘

#### ğŸ” å¯èƒ½åŸå› 
```
- å…³é”®è¯è¿‡äºå…·ä½“
- æ—¶é—´èŒƒå›´é™åˆ¶å¤ªä¸¥
- æ•°æ®åº“é€‰æ‹©ä¸å½“
- æœç´¢è¯­æ³•é”™è¯¯
```

#### âœ… æœç´¢ç­–ç•¥ä¼˜åŒ–
```python
def expand_search_terms(primary_keywords):
    """æ‰©å±•æœç´¢è¯ç­–ç•¥"""
    
    # åŒä¹‰è¯æ‰©å±•
    synonyms = {
        'machine learning': ['ML', 'artificial intelligence', 'deep learning'],
        'natural language processing': ['NLP', 'text mining', 'computational linguistics'],
        'computer vision': ['image processing', 'pattern recognition', 'image analysis']
    }
    
    # ç›¸å…³è¯æ‰©å±•
    related_terms = {
        'transformer': ['attention mechanism', 'BERT', 'GPT', 'neural network'],
        'optimization': ['gradient descent', 'Adam', 'SGD', 'learning rate']
    }
    
    # æ„å»ºå¸ƒå°”æœç´¢
    expanded_query = []
    for keyword in primary_keywords:
        if keyword in synonyms:
            terms = [keyword] + synonyms[keyword]
            expanded_query.append('(' + ' OR '.join(terms) + ')')
        else:
            expanded_query.append(keyword)
    
    return ' AND '.join(expanded_query)

# æœç´¢ç­–ç•¥ç¤ºä¾‹
search_strategies = [
    # ç­–ç•¥1: å®½æ³›æœç´¢
    "transformer AND optimization",
    
    # ç­–ç•¥2: å…·ä½“æœç´¢  
    "transformer AND (efficiency OR acceleration OR compression)",
    
    # ç­–ç•¥3: ç»¼åˆæœç´¢
    "(transformer OR attention mechanism) AND (optimization OR pruning OR quantization)"
]
```

#### ğŸ“Š å¤šæ•°æ®åº“æœç´¢ç­–ç•¥
```python
def multi_database_search(query, databases=['pubmed', 'arxiv', 'ieee']):
    """å¤šæ•°æ®åº“æœç´¢"""
    
    database_configs = {
        'pubmed': {
            'url': 'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/',
            'fields': ['title', 'abstract', 'authors'],
            'format': 'xml'
        },
        'arxiv': {
            'url': 'http://export.arxiv.org/api/query',
            'fields': ['title', 'summary', 'authors'],
            'format': 'atom'
        },
        'ieee': {
            'url': 'https://ieeexploreapi.ieee.org/api/v1/search/articles',
            'fields': ['article_title', 'abstract', 'authors'],
            'format': 'json'
        }
    }
    
    all_results = []
    for db in databases:
        results = search_database(query, database_configs[db])
        all_results.extend(results)
    
    # å»é‡å’Œåˆå¹¶
    unique_results = deduplicate_papers(all_results)
    return unique_results
```

### æœç´¢ç»“æœä¸ç›¸å…³

#### ğŸ” é—®é¢˜åˆ†æ
```
- å…³é”®è¯æ­§ä¹‰
- æœç´¢èŒƒå›´è¿‡å®½  
- ç›¸å…³æ€§è¯„åˆ†ä¸å‡†
- é¢†åŸŸäº¤å‰å¹²æ‰°
```

#### âœ… ç²¾ç¡®åº¦æå‡
```python
def improve_search_precision(query, domain='computer_science'):
    """æå‡æœç´¢ç²¾ç¡®åº¦"""
    
    # é¢†åŸŸé™å®šè¯
    domain_filters = {
        'computer_science': ['algorithm', 'computation', 'software'],
        'biology': ['gene', 'protein', 'cell', 'molecular'],
        'physics': ['quantum', 'particle', 'wave', 'field'],
        'chemistry': ['molecule', 'reaction', 'compound', 'synthesis']
    }
    
    # æ’é™¤æ— å…³è¯
    exclude_terms = {
        'computer_science': ['medical', 'clinical', 'patient'],
        'biology': ['computer', 'algorithm', 'software'],
        'physics': ['social', 'economic', 'business'],
        'chemistry': ['political', 'historical', 'literary']
    }
    
    # æ„å»ºç²¾ç¡®æœç´¢æŸ¥è¯¢
    domain_words = domain_filters.get(domain, [])
    exclude_words = exclude_terms.get(domain, [])
    
    refined_query = query
    if domain_words:
        refined_query += ' AND (' + ' OR '.join(domain_words) + ')'
    if exclude_words:
        refined_query += ' NOT (' + ' OR '.join(exclude_words) + ')'
    
    return refined_query

# è¯­ä¹‰ç›¸å…³æ€§è¿‡æ»¤
def semantic_relevance_filter(papers, query, threshold=0.7):
    """åŸºäºè¯­ä¹‰ç›¸å…³æ€§è¿‡æ»¤"""
    from sentence_transformers import SentenceTransformer
    
    model = SentenceTransformer('all-MiniLM-L6-v2')
    
    query_embedding = model.encode([query])
    relevant_papers = []
    
    for paper in papers:
        abstract = paper.get('abstract', '')
        paper_embedding = model.encode([abstract])
        similarity = cosine_similarity(query_embedding, paper_embedding)[0][0]
        
        if similarity > threshold:
            paper['relevance_score'] = similarity
            relevant_papers.append(paper)
    
    return sorted(relevant_papers, key=lambda x: x['relevance_score'], reverse=True)
```

---

## ğŸš¨ ç³»ç»Ÿé”™è¯¯æ¢å¤

### æ•°æ®ä¸¢å¤±æ¢å¤

#### ğŸ” æ•°æ®ä¸¢å¤±åœºæ™¯
```
- æ„å¤–åˆ é™¤æ–‡ä»¶
- ç³»ç»Ÿå´©æºƒ
- å­˜å‚¨è®¾å¤‡æ•…éšœ
- ç‰ˆæœ¬è¦†ç›–
```

#### âœ… æ¢å¤ç­–ç•¥
```bash
# 1. æœ¬åœ°æ–‡ä»¶æ¢å¤
# Linux/Mac
find /path -name "*deleted_file*" -type f 2>/dev/null
grep -r "content_snippet" /path/to/backup/

# Windows
dir /s "deleted_file*"

# 2. Gitç‰ˆæœ¬æ¢å¤
git log --oneline
git checkout <commit_hash> -- file_path
git reflog  # æŸ¥çœ‹æ‰€æœ‰æ“ä½œå†å²

# 3. ç³»ç»Ÿçº§å¤‡ä»½æ¢å¤
# Time Machine (Mac)
tmutil listlocalsnapshotdates
tmutil restore -v /path/to/backup

# System Restore (Windows)
vssadmin list shadows
```

#### ğŸ›¡ï¸ è‡ªåŠ¨å¤‡ä»½ç³»ç»Ÿ
```python
import shutil
import datetime
from pathlib import Path

class AutoBackup:
    def __init__(self, source_dir, backup_dir, max_backups=10):
        self.source_dir = Path(source_dir)
        self.backup_dir = Path(backup_dir)
        self.max_backups = max_backups
    
    def create_backup(self):
        """åˆ›å»ºè‡ªåŠ¨å¤‡ä»½"""
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_name = f"backup_{timestamp}"
        backup_path = self.backup_dir / backup_name
        
        try:
            shutil.copytree(self.source_dir, backup_path)
            print(f"âœ… å¤‡ä»½æˆåŠŸ: {backup_path}")
            
            # æ¸…ç†æ—§å¤‡ä»½
            self.cleanup_old_backups()
            return backup_path
            
        except Exception as e:
            print(f"âŒ å¤‡ä»½å¤±è´¥: {e}")
            return None
    
    def cleanup_old_backups(self):
        """æ¸…ç†æ—§å¤‡ä»½"""
        backups = sorted(self.backup_dir.glob("backup_*"), key=lambda x: x.stat().st_mtime)
        
        while len(backups) > self.max_backups:
            oldest = backups.pop(0)
            shutil.rmtree(oldest)
            print(f"ğŸ—‘ï¸ åˆ é™¤æ—§å¤‡ä»½: {oldest}")

# ä½¿ç”¨ç¤ºä¾‹
backup_system = AutoBackup("workspace", "backups")
backup_system.create_backup()
```

### ç³»ç»Ÿå´©æºƒæ¢å¤

#### ğŸ” å´©æºƒæ£€æµ‹
```python
import psutil
import logging
from datetime import datetime

class SystemMonitor:
    def __init__(self):
        self.logger = self.setup_logging()
    
    def setup_logging(self):
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('system_monitor.log'),
                logging.StreamHandler()
            ]
        )
        return logging.getLogger(__name__)
    
    def check_system_health(self):
        """æ£€æŸ¥ç³»ç»Ÿå¥åº·çŠ¶å†µ"""
        health_report = {}
        
        # CPUä½¿ç”¨ç‡
        cpu_percent = psutil.cpu_percent(interval=1)
        health_report['cpu'] = cpu_percent
        
        # å†…å­˜ä½¿ç”¨ç‡
        memory = psutil.virtual_memory()
        health_report['memory'] = memory.percent
        
        # ç£ç›˜ä½¿ç”¨ç‡
        disk = psutil.disk_usage('/')
        health_report['disk'] = (disk.used / disk.total) * 100
        
        # è¯„ä¼°ç³»ç»ŸçŠ¶æ€
        if cpu_percent > 90:
            self.logger.warning(f"CPUä½¿ç”¨ç‡è¿‡é«˜: {cpu_percent}%")
        
        if memory.percent > 85:
            self.logger.warning(f"å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜: {memory.percent}%")
        
        if health_report['disk'] > 90:
            self.logger.warning(f"ç£ç›˜ç©ºé—´ä¸è¶³: {health_report['disk']:.1f}%")
        
        return health_report
    
    def emergency_cleanup(self):
        """ç´§æ€¥æ¸…ç†"""
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        import tempfile
        temp_dir = tempfile.gettempdir()
        
        # æ¸…ç†ç¼“å­˜
        cache_dirs = [
            "~/.cache",
            "~/Library/Caches",  # macOS
            "%TEMP%"  # Windows
        ]
        
        for cache_dir in cache_dirs:
            try:
                cache_path = Path(cache_dir).expanduser()
                if cache_path.exists():
                    self.logger.info(f"æ¸…ç†ç¼“å­˜ç›®å½•: {cache_path}")
                    # å®é™…æ¸…ç†é€»è¾‘
            except Exception as e:
                self.logger.error(f"æ¸…ç†å¤±è´¥: {e}")

# è‡ªåŠ¨ç›‘æ§
monitor = SystemMonitor()
health = monitor.check_system_health()
```

---

## ğŸ“ è·å–å¸®åŠ©

### ğŸ“§ é—®é¢˜æŠ¥å‘Šæ¨¡æ¿
```markdown
## é—®é¢˜æŠ¥å‘Š

### åŸºæœ¬ä¿¡æ¯
- æ“ä½œç³»ç»Ÿ: [Windows/macOS/Linux]
- Pythonç‰ˆæœ¬: [x.x.x]  
- Claude Codeç‰ˆæœ¬: [x.x.x]
- é—®é¢˜å‘ç”Ÿæ—¶é—´: [YYYY-MM-DD HH:MM]

### é—®é¢˜æè¿°  
[è¯¦ç»†æè¿°é‡åˆ°çš„é—®é¢˜]

### å¤ç°æ­¥éª¤
1. [æ­¥éª¤1]
2. [æ­¥éª¤2] 
3. [æ­¥éª¤3]

### æœŸæœ›ç»“æœ
[æè¿°æœŸæœ›çš„æ­£å¸¸è¡Œä¸º]

### å®é™…ç»“æœ
[æè¿°å®é™…å‘ç”Ÿçš„æƒ…å†µ]

### é”™è¯¯ä¿¡æ¯
```
[ç²˜è´´å®Œæ•´çš„é”™è¯¯ä¿¡æ¯å’Œå †æ ˆè¿½è¸ª]
```

### ç¯å¢ƒä¿¡æ¯
- å·²å®‰è£…çš„åŒ…: `pip list`
- ç³»ç»Ÿèµ„æº: CPU/å†…å­˜/ç£ç›˜ä½¿ç”¨æƒ…å†µ
- ç½‘ç»œçŠ¶æ€: [ç½‘ç»œè¿æ¥æƒ…å†µ]

### å·²å°è¯•çš„è§£å†³æ–¹æ¡ˆ
[åˆ—å‡ºå·²ç»å°è¯•è¿‡çš„è§£å†³æ–¹æ³•]
```

### ğŸ†˜ ç´§æ€¥è”ç³»æ–¹å¼
```
1. æ£€æŸ¥ç³»ç»Ÿæ—¥å¿—æ–‡ä»¶
   - logs/system.log
   - logs/error.log  
   - logs/debug.log

2. ç¤¾åŒºæ”¯æŒæ¸ é“
   - GitHub Issues: [é¡¹ç›®GitHubåœ°å€]
   - è®¨è®ºè®ºå›: [è®ºå›åœ°å€]
   - ç”¨æˆ·ç¾¤ç»„: [ç¾¤ç»„ä¿¡æ¯]

3. ä¸“ä¸šæ”¯æŒ
   - æŠ€æœ¯æ”¯æŒé‚®ç®±: support@example.com
   - åœ¨çº¿å®¢æœ: [å®¢æœé“¾æ¥]
   - ç”µè¯æ”¯æŒ: [æ”¯æŒç”µè¯]
```

### ğŸ”§ è‡ªåŠ©è¯Šæ–­å·¥å…·
```python
#!/usr/bin/env python3
"""ç³»ç»Ÿè‡ªåŠ©è¯Šæ–­å·¥å…·"""

def run_diagnostics():
    """è¿è¡Œå®Œæ•´çš„ç³»ç»Ÿè¯Šæ–­"""
    
    print("ğŸ” å¼€å§‹ç³»ç»Ÿè¯Šæ–­...")
    
    # 1. ç¯å¢ƒæ£€æŸ¥
    check_environment()
    
    # 2. ä¾èµ–æ£€æŸ¥
    check_dependencies()
    
    # 3. æƒé™æ£€æŸ¥
    check_permissions()
    
    # 4. ç½‘ç»œæ£€æŸ¥
    check_network()
    
    # 5. æ€§èƒ½æ£€æŸ¥
    check_performance()
    
    print("âœ… è¯Šæ–­å®Œæˆï¼Œè¯·æŸ¥çœ‹aboveè¾“å‡º")

if __name__ == "__main__":
    run_diagnostics()
```

---

**é‡åˆ°é—®é¢˜ä¸è¦æ…Œï¼ŒæŒ‰æ­¥éª¤æ’æŸ¥ï¼Œå¿«é€Ÿè§£å†³** ğŸ”§